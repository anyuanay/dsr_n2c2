{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_HzFZNPRCnV"
      },
      "source": [
        "# NER Using sklearn crfsuite\n",
        "Link: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
        "\n",
        "Reference: https://medium.com/data-science-in-your-pocket/named-entity-recognition-ner-using-conditional-random-fields-in-nlp-3660df22e95c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47vmlqjqpzH4"
      },
      "source": [
        "## BIO Annotation for NER\n",
        "Tags of entities are encoded in a BIO-annotation scheme. Each entity is labeled with a B or an I to detect multi-word entities, where B denotes the beginning of an entity and I denote the inside of an entity. O denotes all other words which are not named entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPwVWz-yf1Wq"
      },
      "source": [
        "# CRF Basics\n",
        "Given a sequence $x$, we predict the sequence $y$ of labels for $x$, as follows, where the labels are drawn from a set $\\{l_1, l_2, ..., l_k\\}$:\n",
        "\n",
        "$p_\\theta(y|x) = \\frac{\\exp(\\sum_{j}w_{j}F_{j}(x,y))}{\\sum_{y^{'}}(\\exp(\\sum_{j}w_{j}F_{j}(x,y^{'})))}$\n",
        "\n",
        "$Fⱼ(x,y)$ = summation of values of a feature function for all words. The numerator can be written as:\n",
        "\n",
        "$\\exp(\\sum_{j}w_{j}\\sum_{i}feature\\_function_{j}(x,y_{i}, y_{i-1}, i))$\n",
        "\n",
        "- The inner summation goes from $i=1$ to $i=length$ of a sentence. Hence we are summating the value of any feature function for all words of the sentence\n",
        "\n",
        "If we have a sentence ‘Ram is cool’, the inner summation will add values of the output of the jᵗʰ feature function for all 3 words of the sentence\n",
        "\n",
        "- The outer summation goes from $j=1$ to the total number of feature functions. It is doing something like this: $\\sum_{j}w_{j}\\sum_{i}feature\\_function_{j}(x,y_{i}, y_{i-1}, i))$\n",
        "- $w_{j}$ refers to the weight assigned to a $feature\\_function_{j}$.\n",
        "\n",
        "The denominator sums over all possible sequences.\n",
        "\n",
        "## Feature Functions\n",
        "\n",
        "- embedding of word $w_{i}$\n",
        "- embedding of neighboring words\n",
        "- part of speech of word $w_i$\n",
        "- part of speech of neighboring words\n",
        "- presence in a gazetteer\n",
        "- prefix of word $w_i$ and neighboring words\n",
        "- suffix of word $w_i$ and neighboring words\n",
        "- case of word $w_i$ and neighboring words\n",
        "- shape of word $w_i$ and neighboring words\n",
        "- and lot more...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZklr95lf4g0"
      },
      "source": [
        "# Let's Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ystxj-WwRA-W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "9oC-CLFBZFE_",
        "outputId": "1907aab5-4771-4e22-bd27-8b0678cbeb9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install -U 'scikit-learn<0.24'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiHRRAYORiAq",
        "outputId": "9b1700b7-9fc1-470f-943e-90620a3303fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.63.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "! pip install sklearn-crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn0rEfYERA-b"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS-jjNKgRA-c"
      },
      "source": [
        "## Let's use CoNLL 2002 data to build a NER system\n",
        "\n",
        "CoNLL2002 corpus is available in NLTK. We use Spanish data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2p_BOhURz33",
        "outputId": "32d6e3c4-8415-4c5d-fc26-e1f0f423226c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2002.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('conll2002')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsmI-2vQRA-e",
        "outputId": "7828bfe7-9571-4441-e75c-6dbd57e17c07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.corpus.conll2002.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yaDDBbzRA-g",
        "outputId": "6ab214d6-10a0-43bd-ac64-b120ede68371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.4 s, sys: 175 ms, total: 2.57 s\n",
            "Wall time: 2.91 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0_MLjCRA-h",
        "outputId": "c81687cc-4d4b-44a5-966b-5bac0fab7089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Melbourne', 'NP', 'B-LOC'),\n",
              " ('(', 'Fpa', 'O'),\n",
              " ('Australia', 'NP', 'B-LOC'),\n",
              " (')', 'Fpt', 'O'),\n",
              " (',', 'Fc', 'O'),\n",
              " ('25', 'Z', 'O'),\n",
              " ('may', 'NC', 'O'),\n",
              " ('(', 'Fpa', 'O'),\n",
              " ('EFE', 'NC', 'B-ORG'),\n",
              " (')', 'Fpt', 'O'),\n",
              " ('.', 'Fp', 'O')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlf_jC7MHnDZ",
        "outputId": "0f3ec16c-f64a-498e-abd8-2126bb62eb9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('Melbourne', 'NP', 'B-LOC'),\n",
              "  ('(', 'Fpa', 'O'),\n",
              "  ('Australia', 'NP', 'B-LOC'),\n",
              "  (')', 'Fpt', 'O'),\n",
              "  (',', 'Fc', 'O'),\n",
              "  ('25', 'Z', 'O'),\n",
              "  ('may', 'NC', 'O'),\n",
              "  ('(', 'Fpa', 'O'),\n",
              "  ('EFE', 'NC', 'B-ORG'),\n",
              "  (')', 'Fpt', 'O'),\n",
              "  ('.', 'Fp', 'O')],\n",
              " [('-', 'Fg', 'O')]]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dka58m6RA-i"
      },
      "source": [
        "## Features\n",
        "\n",
        "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. \n",
        "\n",
        "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
        "\n",
        "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-K0EsJQRA-k"
      },
      "outputs": [],
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0] # assume tuples in a sentence (word, pos, tag)\n",
        "    postag = sent[i][1] # the second element in the tuple is pos tag\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:], # last 3 chars\n",
        "        'word[-2:]': word[-2:], # last 2 chars\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2], # the first 2 chars in a pos tag        \n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0] # the previous word\n",
        "        postag1 = sent[i-1][1] # the previous pos tag\n",
        "        features.update({ # add new features to the words except for the first one\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True # a feature for the first word\n",
        "        \n",
        "    if i < len(sent)-1: # words before the last word\n",
        "        word1 = sent[i+1][0] # the next word\n",
        "        postag1 = sent[i+1][1] # the next pos\n",
        "        features.update({ # add features for words except for the last word\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True # a feature for the last word\n",
        "                \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tDdbR4uYnOHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1gqQS3oTnpx"
      },
      "source": [
        "## 自己定义的看这里哦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwKHHwV7bbHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "ac42fa24-ecc1-4917-ee3f-be76bbaea861"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  notesId SentenceId    Word  Start  End Label   Lemma   POS TAG       DEP  \\\n",
              "0  108-04   108-04_1  Record      3    9     O  record  NOUN  NN  compound   \n",
              "1  108-04   108-04_1    date     10   14     O    date  NOUN  NN      ROOT   \n",
              "\n",
              "   Shape  Is_Alpha  Is_Stop  findRxcuiByString  filterByProperty  \\\n",
              "0  Xxxxx      True    False                NaN               NaN   \n",
              "1   xxxx      True    False           899742.0               NaN   \n",
              "\n",
              "   getApproximateMatch  getDrugs getSpellingSuggestions  \n",
              "0             219591.0       NaN                    NaN  \n",
              "1             899742.0       NaN                   date  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d81c709b-d520-4f0b-927d-176c5352a91f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>notesId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Word</th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Label</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Is_Alpha</th>\n",
              "      <th>Is_Stop</th>\n",
              "      <th>findRxcuiByString</th>\n",
              "      <th>filterByProperty</th>\n",
              "      <th>getApproximateMatch</th>\n",
              "      <th>getDrugs</th>\n",
              "      <th>getSpellingSuggestions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>108-04</td>\n",
              "      <td>108-04_1</td>\n",
              "      <td>Record</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "      <td>record</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NN</td>\n",
              "      <td>compound</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219591.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108-04</td>\n",
              "      <td>108-04_1</td>\n",
              "      <td>date</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>O</td>\n",
              "      <td>date</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NN</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>899742.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>899742.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>date</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d81c709b-d520-4f0b-927d-176c5352a91f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d81c709b-d520-4f0b-927d-176c5352a91f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d81c709b-d520-4f0b-927d-176c5352a91f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "a = pd.read_csv(\"./extracted_8.csv\")\n",
        "a.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeSv4PSBUAWK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def df2x_y(input_df: pd.DataFrame):\n",
        "\n",
        "  # extract label and delete unrelated colums\n",
        "  labels = input_df[\"Label\"]\n",
        "  df = input_df.drop(columns = [\"notesId\", \"Start\", \"End\", \"Label\"]).loc[:,[\"SentenceId\",\"Word\"]]\n",
        "\n",
        "  # define stack(list type) to store output features and labels\n",
        "  f_stack = []  # features\n",
        "  l_stack = []  # labels\n",
        "\n",
        "  # initialize a empty predecessor\n",
        "  predecessor = {\"SentenceId\": None}\n",
        "\n",
        "  for index, current in df.iterrows():\n",
        "\n",
        "    # features of current word, related to current word\n",
        "    features = dict(current)\n",
        "\n",
        "    # if the sentenceId of current line and the previous line are the same, then\n",
        "    if current[\"SentenceId\"] == predecessor[\"SentenceId\"]:\n",
        "\n",
        "      # features of current word, related to previous word\n",
        "      features.update(dict((\"pre_\" + key, value)  # pre_: previous word's\n",
        "          for key, value in predecessor.items()\n",
        "          if \"pre_\" not in key))\n",
        "\n",
        "      # features of previous word, related to current word\n",
        "      predecessor.update(dict((\"nex_\" + key, value) # nex_: next word's\n",
        "          for key, value in current.items()))\n",
        "      \n",
        "      # put the new word to the end of its sentence\n",
        "      f_stack[-1].append(features)\n",
        "      l_stack[-1].append(labels[index])\n",
        "\n",
        "    # else, it means here we start a new sentence\n",
        "    else:  # be care of the \"[]\" since you start a new sentence\n",
        "      f_stack.append([features])\n",
        "      l_stack.append([labels[index]])\n",
        "\n",
        "    # replace predecessor word to current word\n",
        "    predecessor = features\n",
        "\n",
        "  return f_stack, l_stack  # X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDd7XTUWbmCt",
        "outputId": "c1ff7822-ecfd-45a9-e61d-0e25b075735a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 97.4 ms, sys: 0 ns, total: 97.4 ms\n",
            "Wall time: 98.9 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "X_train, y_train = df2x_y(a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzLxyImelImL",
        "outputId": "74081020-b18a-4a9d-9da8-e42e27e041e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'SentenceId': '108-04_1',\n",
              "   'Word': 'Record',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': 'date'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': 'date',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': ':',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': 'Record'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': ':',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': '2135',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': 'date'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': '2135',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': '-',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': ':'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': '-',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': '09',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': '2135'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': '09',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': '-',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': '-'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': '-',\n",
              "   'nex_SentenceId': '108-04_1',\n",
              "   'nex_Word': '08',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': '09'},\n",
              "  {'SentenceId': '108-04_1',\n",
              "   'Word': '08',\n",
              "   'pre_SentenceId': '108-04_1',\n",
              "   'pre_Word': '-'}],\n",
              " [{'SentenceId': '108-04_2', 'Word': 'CARDIOLOGY'}],\n",
              " [{'SentenceId': '108-04_3', 'Word': 'GIBSON'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQBnzaFyjmcg",
        "outputId": "db807a66-b638-49c3-8885-268e1196bf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O'], ['O']]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[\"Label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmaexjg5t3JT",
        "outputId": "e7307d8f-7b9a-423b-96b0-6bf8197a225a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O    1085\n",
              "B      42\n",
              "I       1\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBUHsF76RA-m"
      },
      "source": [
        "This is what word2features extracts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI4dxemcVHDa",
        "outputId": "59fe9adc-affc-41bf-e538-13ffa93eacb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Melbourne', 'NP', 'B-LOC')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PWIFW5BRA-m"
      },
      "outputs": [],
      "source": [
        "sent2features(train_sents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvkEIA42RA-n"
      },
      "source": [
        "Extract features from the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUw55g0hRA-o",
        "outputId": "a3fb4908-cac2-4d63-fc87-0d730a4dde84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.44 s, sys: 114 ms, total: 2.55 s\n",
            "Wall time: 3.11 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B8OEomnVVst",
        "outputId": "d7981413-237e-4757-f9d3-eaec92634fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8323, 8323)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "len(X_train), len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZMgtBsZVZO9"
      },
      "outputs": [],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iN4fPUdVrWT",
        "outputId": "278b7a36-bd94-437b-980e-bd0d071a1f13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "y_train[0:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dma0kWovRA-p"
      },
      "source": [
        "## Training\n",
        "\n",
        "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGEY_sgYRA-r",
        "outputId": "6e624013-99a0-4b59-a3d2-8eb9c83691a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 62.9 ms, sys: 1.62 ms, total: 64.5 ms\n",
            "Wall time: 67.3 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs', \n",
        "    c1=0.1, \n",
        "    c2=0.1, \n",
        "    max_iterations=100, \n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiujJHxuRA-s"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. ``sklearn-crfsuite.metrics`` package provides some useful metrics for sequence classification task, including this one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVT8MaSoRA-s",
        "outputId": "b0a38a81-e840-4c29-bdab-174ac68e26de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B', 'I']"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU-6ViykRA-t",
        "outputId": "2dad0675-f392-463b-d107-c3c60aba0726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  Returns\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,average='weighted', labels=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz13JCi_RA-u"
      },
      "source": [
        "Inspect per-class results in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ2BbePPRA-u"
      },
      "outputs": [],
      "source": [
        "# group B and I results\n",
        "sorted_labels = sorted(\n",
        "    labels, \n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0yyk9x8W5qZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M2MYn8XXwCY"
      },
      "outputs": [],
      "source": [
        "y_test_flatten = [lab for sent in y_test for lab in sent]\n",
        "y_pred_flatten = [lab for sent in y_pred for lab in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1y3PdHLW4Tb",
        "outputId": "51ff990b-d259-41d3-dfdc-59f091463fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B      0.000     0.000     0.000         0\n",
            "           I      0.000     0.000     0.000         0\n",
            "\n",
            "   micro avg      0.000     0.000     0.000         0\n",
            "   macro avg      0.000     0.000     0.000         0\n",
            "weighted avg      0.000     0.000     0.000         0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  labels : list, optional\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(\n",
        "    y_test_flatten, y_pred_flatten, labels=sorted_labels, digits=3\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVylsUNbRA-v"
      },
      "source": [
        "## Hyperparameter Optimization\n",
        "\n",
        "To improve quality try to select regularization parameters using randomized search and 3-fold cross-validation.\n",
        "\n",
        "It takes quite a lot of CPU time and RAM (we're fitting a model ``50 * 3 = 150`` times), so grab a tea and be patient, or reduce n_iter in RandomizedSearchCV, or fit model only on a subset of training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "7eyyH6vJRA-w",
        "outputId": "5d713ad2-d22f-4bba-a5a6-4592a8645f81"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-2c24d5fd6e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# define fixed parameters and parameters to search\\ncrf = sklearn_crfsuite.CRF(\\n    algorithm='lbfgs', \\n    max_iterations=100, \\n    all_possible_transitions=True\\n)\\nparams_space = {\\n    'c1': scipy.stats.expon(scale=0.5),\\n    'c2': scipy.stats.expon(scale=0.05),\\n}\\n\\n# use the same metric for evaluation\\nf1_scorer = make_scorer(metrics.flat_f1_score, \\n                        average='weighted', labels=labels)\\n\\n# search\\nrs = RandomizedSearchCV(crf, params_space, \\n                        cv=3, \\n                        verbose=1, \\n                        n_jobs=-1, \\n                        n_iter=50, \\n                        scoring=f1_scorer)\\nrs.fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    803\u001b[0m                                                               n_splits)\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0msplit_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                     \u001b[0;31m# Uses closure to alter the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                     results[\"split%d_%s\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     82\u001b[0m                                 % (repr(estimator), type(estimator)))\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 warnings.warn('From version 0.24, get_params will raise an '\n\u001b[0;32m--> 210\u001b[0;31m                               \u001b[0;34m'AttributeError if a parameter cannot be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                               \u001b[0;34m'retrieved as an instance attribute. Previously '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                               \u001b[0;34m'it would return None.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# define fixed parameters and parameters to search\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs', \n",
        "    max_iterations=100, \n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
        "                        average='weighted', labels=labels)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space, \n",
        "                        cv=3, \n",
        "                        verbose=1, \n",
        "                        n_jobs=-1, \n",
        "                        n_iter=50, \n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dft8sMl8RA-w"
      },
      "source": [
        "Best result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzCG6bIZRA-x"
      },
      "outputs": [],
      "source": [
        "# crf = rs.best_estimator_\n",
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKLXe_6qRA-x"
      },
      "source": [
        "### Check parameter space\n",
        "\n",
        "A chart which shows which ``c1`` and ``c2`` values have RandomizedSearchCV checked. Red color means better results, blue means worse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "RmfqTnwLRA-y",
        "outputId": "8923f498-2dd2-4ed2-a383-a985eb93292c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-dc5359a36b19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'cv_results_'"
          ]
        }
      ],
      "source": [
        "_x = [s['c1'] for s in rs.cv_results_['params']]\n",
        "_y = [s['c2'] for s in rs.cv_results_['params']]\n",
        "_c = rs.cv_results_['mean_test_score']\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(12, 12)\n",
        "ax = plt.gca()\n",
        "ax.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('C1')\n",
        "ax.set_ylabel('C2')\n",
        "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
        "    min(_c), max(_c)\n",
        "))\n",
        "\n",
        "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
        "\n",
        "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2_ZBhX6RA-y"
      },
      "source": [
        "## Check best estimator on our test data\n",
        "\n",
        "As you can see, quality is improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGMNcQL7RA-y"
      },
      "outputs": [],
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSixwPD-RA-z"
      },
      "source": [
        "## Let's check what classifier learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKA1IeGnRA-z"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEfi-B2QRA-z"
      },
      "source": [
        "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized.\n",
        "\n",
        "Check the state features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sfbqVzmRA-z"
      },
      "outputs": [],
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0t6srZORA-0"
      },
      "source": [
        "\n",
        "\n",
        "Some observations:\n",
        "\n",
        "   * **9.385823 B-ORG word.lower():psoe-progresistas** - the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n",
        "   * **4.636151 I-LOC -1:word.lower():calle:** \"calle\" is a street in Spanish; model learns that if a previous word was \"calle\" then the token is likely a part of location;\n",
        "   * **-5.632036 O word.isupper()**, **-8.215073 O word.istitle()** : UPPERCASED or TitleCased words are likely entities of some kind;\n",
        "   * **-2.097561 O postag:NP** - proper nouns (NP is a proper noun in the Spanish tagset) are often entities.\n",
        "\n",
        "What to do next\n",
        "\n",
        "    * Load 'testa' Spanish data.\n",
        "    * Use it to develop better features and to find best model parameters.\n",
        "    * Apply the model to 'testb' data again.\n",
        "\n",
        "The model in this notebook is just a starting point; you certainly can do better!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3wQgdbRA-0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "“NER-sklearn-crfsuite-example-CoNLL.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [
        "Z2_ZBhX6RA-y",
        "bSixwPD-RA-z"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}